{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8abac33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    }
   ],
   "source": [
    "print(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "584798ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "import os\n",
    "GROQ_API_KEY = os.environ.get(\"GROQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4fa564db",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"deepseek-r1-distill-llama-70b\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcec12d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='<think>\\n\\n</think>\\n\\nHello! How can I assist you today?', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 4, 'total_tokens': 18, 'completion_time': 0.071092337, 'prompt_time': 9.1129e-05, 'queue_time': 0.056855410999999995, 'total_time': 0.071183466}, 'model_name': 'deepseek-r1-distill-llama-70b', 'system_fingerprint': 'fp_1bbe7845ec', 'finish_reason': 'stop', 'logprobs': None}, id='run--8a9c0a9c-2a5d-40a4-b54d-468038e9a683-0', usage_metadata={'input_tokens': 4, 'output_tokens': 14, 'total_tokens': 18})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "llm = ChatGroq(model=model_name, api_key=GROQ_API_KEY)\n",
    "llm.invoke(\"hi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b597b70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "\n",
      "</think>\n",
      "\n",
      "Hello! How can I assist you today? ðŸ˜Š\n"
     ]
    }
   ],
   "source": [
    "# we are using deepseek, which is a reasoning model \n",
    "print(llm.invoke(\"hi\").content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7ed925ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "from langchain_core.messages import BaseMessage, HumanMessage, AIMessage\n",
    "from langgraph.graph import StateGraph, MessagesState, START, END\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c068f82a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_model(state: HumanMessage):\n",
    "    messages = state[\"messages\"]\n",
    "    response = llm.invoke(messages)\n",
    "    return {\"messages\" : response}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f372c7",
   "metadata": {},
   "source": [
    "# Design a workflow with binding tool calls "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "790093a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def search(query: str):\n",
    "    \"\"\"get weather report tool\"\"\"\n",
    "    if \"delhi\" in query.lower():\n",
    "        return \"the temp is 45 degree and sunny\"\n",
    "    return \"the temp is 25 degree and cloudy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6aa23af3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the temp is 25 degree and cloudy'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.invoke(\"what is a tempurature in kashmir?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c056856e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructuredTool(name='search', description='get weather report tool', args_schema=<class 'langchain_core.utils.pydantic.search'>, func=<function search at 0x10b32d300>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3fc86ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this search is of custom tool of type StructuredTool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2a55a26e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='<think>\\n\\n</think>\\n\\nAs of my last update in July 2024, I cannot provide real-time weather information. However, Delhi generally experiences a humid subtropical climate with extreme summer and winter seasons. Summers are very hot, with temperatures often reaching 45Â°C (113Â°F) or more, while winters can be quite cold, with temperatures dropping to around 2-5Â°C (36-41Â°F). The monsoon season typically occurs between July and September, bringing significant rainfall. For the most current weather information, I recommend checking a reliable weather service or app.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 115, 'prompt_tokens': 11, 'total_tokens': 126, 'completion_time': 0.418181818, 'prompt_time': 0.000287276, 'queue_time': 0.052630083999999994, 'total_time': 0.418469094}, 'model_name': 'deepseek-r1-distill-llama-70b', 'system_fingerprint': 'fp_1bbe7845ec', 'finish_reason': 'stop', 'logprobs': None}, id='run--70b6ea18-dab7-4ded-85f8-0c475c15e9c0-0', usage_metadata={'input_tokens': 11, 'output_tokens': 115, 'total_tokens': 126})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"what is a weather in delhi?\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39afbd17",
   "metadata": {},
   "source": [
    "## Binding the tool to the LLM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2a55993f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [search]\n",
    "llm_with_tools = llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2eb6409",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='' additional_kwargs={'tool_calls': [{'id': 'zjp3kg282', 'function': {'arguments': '{\"query\":\"weather in Delhi\"}', 'name': 'search'}, 'type': 'function'}]} response_metadata={'token_usage': {'completion_tokens': 231, 'prompt_tokens': 128, 'total_tokens': 359, 'completion_time': 0.928713346, 'prompt_time': 0.008214311, 'queue_time': 0.052300009, 'total_time': 0.936927657}, 'model_name': 'deepseek-r1-distill-llama-70b', 'system_fingerprint': 'fp_1bbe7845ec', 'finish_reason': 'tool_calls', 'logprobs': None} id='run--1ef8289a-587d-45f1-9ed2-8d5a3b0689e5-0' tool_calls=[{'name': 'search', 'args': {'query': 'weather in Delhi'}, 'id': 'zjp3kg282', 'type': 'tool_call'}] usage_metadata={'input_tokens': 128, 'output_tokens': 231, 'total_tokens': 359}\n"
     ]
    }
   ],
   "source": [
    "response = llm_with_tools.invoke(\"what is the weather in delhi ?\")\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9f296b15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello there! How can I help you today?\n"
     ]
    }
   ],
   "source": [
    "GEMINI_API_KEY = os.getenv(\"GEMINI_API_KEY\")\n",
    "from langchain_google_genai import GoogleGenerativeAI\n",
    "gemini_llm = GoogleGenerativeAI(\n",
    "    model=\"gemini-1.5-flash\",\n",
    "    temperature=0.2,\n",
    "    google_api_key=GEMINI_API_KEY,\n",
    "    max_output_tokens=1024,)\n",
    "response = gemini_llm.invoke(\"hello gemini\")\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c955ba1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "gemini_llm = init_chat_model(\"gemini-2.0-flash\", model_provider=\"google_genai\",  google_api_key=GEMINI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4e3edd4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini_llm_with_tools = gemini_llm.bind_tools(tools)\n",
    "response = gemini_llm_with_tools.invoke(\"what is the weather in delhi\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8cac9dac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a101715f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_model(state:MessagesState):\n",
    "    question=state[\"messages\"]\n",
    "    response=llm_with_tools.invoke(question)\n",
    "    return {\"messages\":[response]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "27bff868",
   "metadata": {},
   "outputs": [],
   "source": [
    "input={\"messages\":[\"what is a weather in delhi?\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b3fe5a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "response=call_model(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b224d615",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response[\"messages\"][-1].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b425681f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'search',\n",
       "  'args': {'query': 'weather in Delhi'},\n",
       "  'id': 'mv0nkk632',\n",
       "  'type': 'tool_call'}]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response[\"messages\"][-1].tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a9bcf63e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  search (mv0nkk632)\n",
      " Call ID: mv0nkk632\n",
      "  Args:\n",
      "    query: weather in Delhi\n"
     ]
    }
   ],
   "source": [
    "response[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf39596",
   "metadata": {},
   "source": [
    "# Creating a langggraph workflow with binding llm with different tools "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "dbfd68b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def router(state: MessagesState):\n",
    "    print(\"----- router ------\")\n",
    "\n",
    "    # route the query for llm call with tools or \n",
    "    message = state[\"messages\"][-1]\n",
    "\n",
    "    if message.tool_calls:\n",
    "        return \"tools\"\n",
    "    \n",
    "    return END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2aa8c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def weather(state: MessagesState):\n",
    "    \"\"\"get weather report tool\"\"\"\n",
    "    query = state[\"messages\"][-1]\n",
    "    if \"delhi\" in query.lower():\n",
    "        return \"the temp is 45 degree and sunny\"\n",
    "    return \"the temp is 25 degree and cloudy\"\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "802a93d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def finance(state : MessagesState):\n",
    "    \"\"\" get finance report \"\"\"\n",
    "    query = state[\"messages\"][-1]\n",
    "\n",
    "    if \"gdp\" in query.lower():\n",
    "        return \"The GDP of India is around 3 Trillion dollars\"\n",
    "    \n",
    "    return \"Business news as normal\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "3381ab90",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def science(state : MessagesState):\n",
    "    \"\"\" get science report \"\"\"\n",
    "    query = state[\"messages\"][-1]\n",
    "\n",
    "    if \"colbert\" in query.lower():\n",
    "        return \"Late Intercation is being used\"\n",
    "    \n",
    "    return \"Gneral Retrieval techniques\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf7ff88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "1e680e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [weather, finance, science]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "a5d78da9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[StructuredTool(name='weather', description='get weather report tool', args_schema=<class 'langchain_core.utils.pydantic.weather'>, func=<function weather at 0x110294fe0>),\n",
       " StructuredTool(name='finance', description='get finance report', args_schema=<class 'langchain_core.utils.pydantic.finance'>, func=<function finance at 0x110267380>),\n",
       " StructuredTool(name='science', description='get science report', args_schema=<class 'langchain_core.utils.pydantic.science'>, func=<function science at 0x110267060>)]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "149a1ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_model(state: MessagesState):\n",
    "    message = state[\"messages\"]\n",
    "    print(\"--- calling LLM ---\")\n",
    "    print(message)\n",
    "\n",
    "    prompt = \"\"\"\n",
    "      You are provided with different tools integrated within yourself\n",
    "\"\"\"\n",
    "    llm_with_tools = llm.bind_tools(tools)\n",
    "    response = llm_with_tools.invoke(message)\n",
    "    print(\"response\")\n",
    "    return {\"messages\": [response]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "c83d1dbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tools(tags=None, recurse=True, explode_args=False, func_accepts_config=True, func_accepts={'store': ('__pregel_store', None)}, tools_by_name={'weather': StructuredTool(name='weather', description='get weather report tool', args_schema=<class 'langchain_core.utils.pydantic.weather'>, func=<function weather at 0x110294fe0>), 'finance': StructuredTool(name='finance', description='get finance report', args_schema=<class 'langchain_core.utils.pydantic.finance'>, func=<function finance at 0x110267380>), 'science': StructuredTool(name='science', description='get science report', args_schema=<class 'langchain_core.utils.pydantic.science'>, func=<function science at 0x110267060>)}, tool_to_state_args={'weather': {}, 'finance': {}, 'science': {}}, tool_to_store_arg={'weather': None, 'finance': None, 'science': None}, handle_tool_errors=True, messages_key='messages')"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langgraph.prebuilt import ToolNode\n",
    "tool_node = ToolNode(tools)\n",
    "tool_node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "c9a14800",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = StateGraph(MessagesState)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "af3b39cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x110ec6550>"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow.add_node(\"llmwithtool\", call_model)\n",
    "# Binded with all the tools \n",
    "# workflow.add_node(\"mytools\", tool_node)\n",
    "\n",
    "# we are having a toolnode instead of separately tools, beter keep a toolnode instead of eachsingle tools\n",
    "workflow.add_node(\"mytools\", tool_node)\n",
    "\n",
    "workflow.add_edge(START, \"llmwithtool\")\n",
    "workflow.add_edge(\"mytools\", END)\n",
    "workflow.add_edge(\"mytools\", \"llmwithtool\" )\n",
    "\n",
    "workflow.add_conditional_edges(\"llmwithtool\", router, {\n",
    "    \"tools\": \"mytools\",\n",
    "    END : END\n",
    "})\n",
    "workflow.set_entry_point(\"llmwithtool\")\n",
    "# workflow.set_finish_point(END)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "a59090c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "app2=workflow.compile()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "0c46489c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "display(Image(app2.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "33ebc820",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- calling LLM ---\n",
      "[HumanMessage(content='what is a weather in bengraluru?', additional_kwargs={}, response_metadata={}, id='568db8c5-7387-4cc3-a311-3e520cdf7558')]\n"
     ]
    },
    {
     "ename": "BadRequestError",
     "evalue": "Error code: 400 - {'error': {'message': \"Failed to call a function. Please adjust your prompt. See 'failed_generation' for more details.\", 'type': 'invalid_request_error', 'code': 'tool_use_failed', 'failed_generation': '<tool_call>{\"name\": \"weather\", \"arguments\": {\"city\": \"Bangalore\"}}</tool_call>'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mBadRequestError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[105]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m response=\u001b[43mapp2\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mwhat is a weather in bengraluru?\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Krish-Naik-Course-Agentic AI/agentic-ai-course/venv/lib/python3.11/site-packages/langgraph/pregel/__init__.py:2719\u001b[39m, in \u001b[36mPregel.invoke\u001b[39m\u001b[34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, checkpoint_during, debug, **kwargs)\u001b[39m\n\u001b[32m   2716\u001b[39m chunks: \u001b[38;5;28mlist\u001b[39m[Union[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any], Any]] = []\n\u001b[32m   2717\u001b[39m interrupts: \u001b[38;5;28mlist\u001b[39m[Interrupt] = []\n\u001b[32m-> \u001b[39m\u001b[32m2719\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2720\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   2721\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2722\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2723\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2724\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2725\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2726\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcheckpoint_during\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcheckpoint_during\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2727\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdebug\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdebug\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2728\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2729\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   2730\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[32m   2731\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2732\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   2733\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;129;43;01mand\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mints\u001b[49m\u001b[43m \u001b[49m\u001b[43m:=\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mINTERRUPT\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\n\u001b[32m   2734\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Krish-Naik-Course-Agentic AI/agentic-ai-course/venv/lib/python3.11/site-packages/langgraph/pregel/__init__.py:2436\u001b[39m, in \u001b[36mPregel.stream\u001b[39m\u001b[34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, checkpoint_during, debug, subgraphs)\u001b[39m\n\u001b[32m   2434\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m loop.match_cached_writes():\n\u001b[32m   2435\u001b[39m             loop.output_writes(task.id, task.writes, cached=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m2436\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrunner\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2437\u001b[39m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrites\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2438\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstep_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2439\u001b[39m \u001b[43m            \u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2440\u001b[39m \u001b[43m            \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43maccept_push\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2441\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   2442\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# emit output\u001b[39;49;00m\n\u001b[32m   2443\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01myield from\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2444\u001b[39m \u001b[38;5;66;03m# emit output\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[89]\u001b[39m\u001b[32m, line 10\u001b[39m, in \u001b[36mcall_model\u001b[39m\u001b[34m(state)\u001b[39m\n\u001b[32m      6\u001b[39m     prompt = \u001b[33m\"\"\"\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[33m      You are provided with different tools integrated within yourself\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[33m\"\"\"\u001b[39m\n\u001b[32m      9\u001b[39m     llm_with_tools = llm.bind_tools(tools)\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m     response = \u001b[43mllm_with_tools\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     11\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m: [response]}\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Krish-Naik-Course-Agentic AI/agentic-ai-course/venv/lib/python3.11/site-packages/langchain_core/runnables/base.py:5431\u001b[39m, in \u001b[36mRunnableBindingBase.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   5424\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m   5425\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m   5426\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   5429\u001b[39m     **kwargs: Optional[Any],\n\u001b[32m   5430\u001b[39m ) -> Output:\n\u001b[32m-> \u001b[39m\u001b[32m5431\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbound\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   5432\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   5433\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_merge_configs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5434\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43m{\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5435\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Krish-Naik-Course-Agentic AI/agentic-ai-course/venv/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py:372\u001b[39m, in \u001b[36mBaseChatModel.invoke\u001b[39m\u001b[34m(self, input, config, stop, **kwargs)\u001b[39m\n\u001b[32m    360\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    361\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m    362\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    367\u001b[39m     **kwargs: Any,\n\u001b[32m    368\u001b[39m ) -> BaseMessage:\n\u001b[32m    369\u001b[39m     config = ensure_config(config)\n\u001b[32m    370\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[32m    371\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mChatGeneration\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m--> \u001b[39m\u001b[32m372\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    373\u001b[39m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    374\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    375\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcallbacks\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    376\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtags\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    377\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    378\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_name\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    379\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    380\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    381\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m.generations[\u001b[32m0\u001b[39m][\u001b[32m0\u001b[39m],\n\u001b[32m    382\u001b[39m     ).message\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Krish-Naik-Course-Agentic AI/agentic-ai-course/venv/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py:957\u001b[39m, in \u001b[36mBaseChatModel.generate_prompt\u001b[39m\u001b[34m(self, prompts, stop, callbacks, **kwargs)\u001b[39m\n\u001b[32m    948\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    949\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate_prompt\u001b[39m(\n\u001b[32m    950\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    954\u001b[39m     **kwargs: Any,\n\u001b[32m    955\u001b[39m ) -> LLMResult:\n\u001b[32m    956\u001b[39m     prompt_messages = [p.to_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[32m--> \u001b[39m\u001b[32m957\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Krish-Naik-Course-Agentic AI/agentic-ai-course/venv/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py:776\u001b[39m, in \u001b[36mBaseChatModel.generate\u001b[39m\u001b[34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[39m\n\u001b[32m    773\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(input_messages):\n\u001b[32m    774\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    775\u001b[39m         results.append(\n\u001b[32m--> \u001b[39m\u001b[32m776\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    777\u001b[39m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    778\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    779\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    780\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    781\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    782\u001b[39m         )\n\u001b[32m    783\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    784\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Krish-Naik-Course-Agentic AI/agentic-ai-course/venv/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py:1022\u001b[39m, in \u001b[36mBaseChatModel._generate_with_cache\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1020\u001b[39m     result = generate_from_stream(\u001b[38;5;28miter\u001b[39m(chunks))\n\u001b[32m   1021\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m inspect.signature(\u001b[38;5;28mself\u001b[39m._generate).parameters.get(\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1022\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1023\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m   1024\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1025\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1026\u001b[39m     result = \u001b[38;5;28mself\u001b[39m._generate(messages, stop=stop, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Krish-Naik-Course-Agentic AI/agentic-ai-course/venv/lib/python3.11/site-packages/langchain_groq/chat_models.py:498\u001b[39m, in \u001b[36mChatGroq._generate\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m    493\u001b[39m message_dicts, params = \u001b[38;5;28mself\u001b[39m._create_message_dicts(messages, stop)\n\u001b[32m    494\u001b[39m params = {\n\u001b[32m    495\u001b[39m     **params,\n\u001b[32m    496\u001b[39m     **kwargs,\n\u001b[32m    497\u001b[39m }\n\u001b[32m--> \u001b[39m\u001b[32m498\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmessage_dicts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    499\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._create_chat_result(response)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Krish-Naik-Course-Agentic AI/agentic-ai-course/venv/lib/python3.11/site-packages/groq/resources/chat/completions.py:368\u001b[39m, in \u001b[36mCompletions.create\u001b[39m\u001b[34m(self, messages, model, exclude_domains, frequency_penalty, function_call, functions, include_domains, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, n, parallel_tool_calls, presence_penalty, reasoning_effort, reasoning_format, response_format, search_settings, seed, service_tier, stop, store, stream, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m    181\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate\u001b[39m(\n\u001b[32m    182\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    183\u001b[39m     *,\n\u001b[32m   (...)\u001b[39m\u001b[32m    229\u001b[39m     timeout: \u001b[38;5;28mfloat\u001b[39m | httpx.Timeout | \u001b[38;5;28;01mNone\u001b[39;00m | NotGiven = NOT_GIVEN,\n\u001b[32m    230\u001b[39m ) -> ChatCompletion | Stream[ChatCompletionChunk]:\n\u001b[32m    231\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    232\u001b[39m \u001b[33;03m    Creates a model response for the given chat conversation.\u001b[39;00m\n\u001b[32m    233\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    366\u001b[39m \u001b[33;03m      timeout: Override the client-level default timeout for this request, in seconds\u001b[39;00m\n\u001b[32m    367\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m368\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    369\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/openai/v1/chat/completions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    370\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    371\u001b[39m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    372\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    373\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    374\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mexclude_domains\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mexclude_domains\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    375\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfrequency_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    376\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunction_call\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    377\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunctions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    378\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minclude_domains\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43minclude_domains\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    379\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogit_bias\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    380\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    381\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_completion_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    382\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    383\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    384\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mn\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    385\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mparallel_tool_calls\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    386\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpresence_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    387\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mreasoning_effort\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_effort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    388\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mreasoning_format\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    389\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mresponse_format\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    390\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msearch_settings\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msearch_settings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    391\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mseed\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    392\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mservice_tier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    393\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstop\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    394\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstore\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    395\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    396\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtemperature\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    397\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtool_choice\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    398\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtools\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    399\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_logprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    400\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_p\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    401\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    402\u001b[39m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    403\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    404\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    405\u001b[39m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    406\u001b[39m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m    407\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    408\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    409\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    410\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    411\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Krish-Naik-Course-Agentic AI/agentic-ai-course/venv/lib/python3.11/site-packages/groq/_base_client.py:1225\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1211\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1212\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1213\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1220\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1221\u001b[39m ) -> ResponseT | _StreamT:\n\u001b[32m   1222\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1223\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001b[32m   1224\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1225\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Krish-Naik-Course-Agentic AI/agentic-ai-course/venv/lib/python3.11/site-packages/groq/_base_client.py:1034\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1031\u001b[39m             err.response.read()\n\u001b[32m   1033\u001b[39m         log.debug(\u001b[33m\"\u001b[39m\u001b[33mRe-raising status error\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1034\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._make_status_error_from_response(err.response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1036\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m   1038\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mcould not resolve response (should never happen)\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mBadRequestError\u001b[39m: Error code: 400 - {'error': {'message': \"Failed to call a function. Please adjust your prompt. See 'failed_generation' for more details.\", 'type': 'invalid_request_error', 'code': 'tool_use_failed', 'failed_generation': '<tool_call>{\"name\": \"weather\", \"arguments\": {\"city\": \"Bangalore\"}}</tool_call>'}}",
      "During task with name 'llmwithtool' and id '22e90da3-d545-fbeb-2cf8-4121631ba6a7'"
     ]
    }
   ],
   "source": [
    "response=app2.invoke({\"messages\":[\"what is a weather in bengraluru?\"]})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a16b1e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
